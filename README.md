[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/release/python-3120/)
![PyTorch Lightning](https://img.shields.io/badge/pytorch-lightning-blue.svg?logo=PyTorch%20Lightning)
![HuggingFace](https://img.shields.io/badge/ğŸ¤—-HuggingFace-yellow.svg)

# OcularAI - Multi-Label Retinal Disease Classification using Vision Transformers

A deep learning pipeline for **multi-label classification of retinal diseases** from fundus images using state-of-the-art Vision Transformer architectures and transfer learning techniques.

**Author:** Chidwipak Kuppani

> [!NOTE]
> **Development Context**
> This project was developed in **July 2025** on a remote SSH college system (GPU server: RTX 6000) provided for research and coursework. All development, training, and evaluation was conducted on these remote servers, which is why the project is being pushed to GitHub now (January 2026) rather than during the original development period.
>
> **Why Now?**
> As I'm applying for internships and research positions, I'm consolidating my work from various remote systems into a public portfolio on GitHub. This project represents authentic research work completed during my academic studies, now being shared for professional opportunities.

---

## ğŸ¯ Overview

This project implements and compares multiple pre-trained Vision Transformer models for detecting ocular diseases from the **ODIR-5K dataset** (Ocular Disease Intelligent Recognition). The system performs multi-label classification of fundus images into 4 categories:

| Code | Disease | Description |
|------|---------|-------------|
| **N** | Normal | Healthy retina with low optic cup to disc ratio |
| **D** | Diabetic Retinopathy | Micro-aneurysms, hemorrhages (red spots), exudates (yellow spots) |
| **C** | Cataract | Blurred/absent basic anatomical structures |
| **M** | Pathological Myopia | Peri-papillary atrophy around optic disc |

---

## âœ¨ Features

- ğŸ¥ **Multi-label classification** - Detect multiple conditions per image
- ğŸ”¬ **4 Model Architectures** - ViT, DeiT, Swin Transformer, ResNet-50
- ğŸ“Š **Attention Visualization** - Interpretability through attention maps
- âš¡ **PyTorch Lightning** - Scalable, professional training pipeline
- ğŸ¤— **HuggingFace Transformers** - State-of-the-art pretrained models
- ğŸ“ˆ **Comprehensive Metrics** - F1-Score, Macro F1, Ranking Average Precision

---

## ğŸ“Š Experimental Results

### Model Comparison on ODIR Test Set

| Model | Normal (N) | Diabetic Retinopathy (D) | Cataract (C) | Myopia (M) | **F1 Macro** | Ranking AP |
|-------|------------|--------------------------|--------------|------------|--------------|------------|
| **Swin** | **80.8%** | 61.1% | 86.3% | 95.9% | **81.1%** | **81.0%** |
| DeiT | 78.9% | 63.5% | 85.1% | **98.0%** | 81.4% | 80.8% |
| ViT | 76.8% | 63.4% | 83.3% | 95.9% | 79.9% | 78.6% |
| ResNet-50 | 80.1% | 53.7% | 79.1% | **98.0%** | 77.7% | 79.4% |

> **Key Finding:** Vision Transformers consistently outperform the CNN baseline (ResNet-50) across all metrics.

### Per-Class Analysis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    F1 Score Performance (%)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       Class          â”‚  Swin  â”‚  DeiT  â”‚  ViT   â”‚ ResNet-50 â”‚  Best  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Normal (N)           â”‚  80.8  â”‚  78.9  â”‚  76.8  â”‚   80.1    â”‚  Swin  â”‚
â”‚ Diabetic Retinop.(D) â”‚  61.1  â”‚  63.5  â”‚  63.4  â”‚   53.7    â”‚  DeiT  â”‚
â”‚ Cataract (C)         â”‚  86.3  â”‚  85.1  â”‚  83.3  â”‚   79.1    â”‚  Swin  â”‚
â”‚ Myopia (M)           â”‚  95.9  â”‚  98.0  â”‚  95.9  â”‚   98.0    â”‚  DeiT  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Findings

1. **Swin Transformer achieves best overall performance** - Highest Ranking Average Precision (81.0%)
2. **Myopia detection is highly accurate** - All models achieve >95% F1
3. **Diabetic Retinopathy is most challenging** - Best F1 is 63.5% (DeiT)
4. **Vision Transformers outperform CNN baseline** - Swin exceeds ResNet by 3.4% in F1 Macro

### Dataset Statistics

| Label | Class | Training | Validation | Testing | Total |
|-------|-------|----------|------------|---------|-------|
| N | Normal | 1337 | 325 | 402 | 2064 |
| D | Diabetic Retinopathy | 1079 | 285 | 354 | 1718 |
| C | Cataract | 195 | 49 | 58 | 302 |
| M | Pathological Myopia | 163 | 39 | 53 | 255 |

### Training Configuration

| Parameter | Value |
|-----------|-------|
| Optimizer | AdamW |
| Learning Rate | 5Ã—10â»â´ |
| Batch Size | 16 |
| Max Epochs | 400 |
| Early Stopping | 10 epochs patience |
| Loss Function | Weighted BCE (class-balanced) |
| GPU | RTX 6000 |

---

## ğŸ“ Project Structure

```
OcularAI/
â”œâ”€â”€ core/                           # Core modules
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ classifiers.py          # 4 model implementations
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ dataset.py              # Dataset class
â”‚   â”œâ”€â”€ config.py                   # Hyperparameters
â”‚   â””â”€â”€ utils.py                    # Utilities
â”œâ”€â”€ pipeline/                       # Training pipeline
â”‚   â”œâ”€â”€ train.py                    # Training script
â”‚   â”œâ”€â”€ visualization/
â”‚   â”‚   â””â”€â”€ attention.py            # Attention maps
â”‚   â””â”€â”€ analysis/
â”‚       â”œâ”€â”€ eda.py                  # Exploratory analysis
â”‚       â””â”€â”€ statistics.py           # Dataset statistics
â”œâ”€â”€ outputs/                        # Training outputs
â”‚   â””â”€â”€ training_logs/              # Experiment logs
â”œâ”€â”€ data/                           # Dataset files
â”‚   â””â”€â”€ ODIR/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/OcularAI.git
cd OcularAI

# Install dependencies
pip install -r requirements.txt
```

### Training

```bash
cd pipeline
python train.py
```

Configure the model in `core/config.py`:
```python
# Options: SWIN, VIT, DeiT, ResNet
model_processor = 'SWIN'  # Best performing model
```

### Attention Visualization

```bash
cd pipeline/visualization
python attention.py
```

---

## ğŸ”§ Model Architectures

| Model | Pre-trained Source | Key Features |
|-------|-------------------|--------------|
| **Swin** | microsoft/swin-tiny-patch4-window7-224 | Shifted window attention, hierarchical design |
| **DeiT** | facebook/deit-base-distilled-patch16-224 | Knowledge distillation, data-efficient |
| **ViT** | google/vit-base-patch16-224 | Original vision transformer architecture |
| **ResNet-50** | microsoft/resnet-50 | CNN baseline with residual connections |

---

## ğŸ“š Dataset

**ODIR-5K** (Ocular Disease Intelligent Recognition)
- **Source:** Peking University / Shanggong Medical Technology Co., Ltd.
- **Images:** ~5000 pairs of left/right fundus photographs
- **Split:** Train (70%) / Validation (15%) / Test (15%)
- **Preprocessing:** Quality filtering, 224Ã—224 resize, stratified splitting

---

## ğŸ“‹ Requirements

- Python 3.10+
- PyTorch 2.2+
- PyTorch Lightning 2.2+
- HuggingFace Transformers 4.39+
- CUDA-capable GPU (recommended: RTX 6000 or equivalent)

---

## ğŸ“– Citation

If you use this work, please cite:

```bibtex
@software{ocularai2024,
  author = {Kuppani, Chidwipak},
  title = {OcularAI: Multi-Label Retinal Disease Classification using Vision Transformers},
  year = {2024},
  url = {https://github.com/YOUR_USERNAME/OcularAI}
}
```

---

## ğŸ™ Acknowledgements

- [ODIR-5K Dataset](https://odir2019.grand-challenge.org/dataset/) - Peking University
- [HuggingFace Transformers](https://huggingface.co/transformers/)
- [PyTorch Lightning](https://lightning.ai/)

---

## ğŸ“„ License

MIT License
